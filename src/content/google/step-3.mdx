---
title: "Step 3 · Responsible AI & Model Documentation"
vendor: "google"
ordinal: 3
slug: "/google/step-3"
lastReviewed: "2025-08-06"
---

# Step 3: Advanced Responsible AI — Model Documentation & Risk Awareness 

## Goal  
Demonstrate that you can go beyond ethical awareness by clearly communicating the limitations and risks of your generative AI models—just like professional AI teams do.

In Step 1, you were introduced to Responsible AI principles. Now, you’ll apply those ideas by creating **structured documentation** that communicates your model’s purpose, limitations, intended use, and ethical concerns. This is how responsible AI is practiced in real-world settings. 

1. Use a [Model Card](https://modelcards.withgoogle.com/) or an “About this Model” section in your README. Explain: 
    - What the model does
    - What data it was trained on
    - Where it may fail (e.g., bias, hallucination) 
    - What safety features are in place (e.g., filters, grounding) 
2. Explore the [Model Context Protocol (MCP)](https://www.anthropic.com/news/model-context-protocol) — a new way of standardizing how AI systems communicate risk and context. MCP helps developers: 
    - Declare model capabilities and limitations 
    - Set expectations for what an AI system *should and should not* do 
    - Offer transparency to users, product teams, and auditors
3. Showcase it on GitHub: Add a “Responsible AI” section to your README or app interface. 

## Example Documentation
Example resumé bullet: *“Created Model Card and applied MCP-style documentation for a generative AI chatbot, outlining intended use, known risks, and safety filters.”*

Example LinkedIn post: *“Launched a Q&A bot built with PaLM2 via Vertex AI—and included a Model Card that defines its scope and ethical boundaries. Being transparent about AI limitations is just as important as the code itself. #ResponsibleAI #VertexAI #ModelCard”*
